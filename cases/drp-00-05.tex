\subsection{DRP-00-05: Execution of the DRP Science Payload by the Batch Production Service}
\label{drp-00-05}

\subsubsection{Requirements}

For LDM-503-2 the test is limited to: DMS-REQ-0106,DMS-REQ-0293,DMS-REQ-0302,DMS-REQ-0303.

\subsubsection{Test items}

This test will check that the DRP Science Payload can be executed
using a specific version of the Batch Production Service provided
by the LSST Data Facility.  Since the outputs are stored in the
Data Backbone, it too is a component of this test.

\subsubsection{Intercase dependencies}

\begin{itemize}

  \item{\hyperref[drp-00-00]{DRP-00-00}}

\end{itemize}

\subsubsection{Environmental needs}


\paragraph{Hardware}\label{sec:hardware}

This test case shall be executed on a testbed at NCSA.

For LDM-503-2, this NCSA testbed includes:
\begin{itemize}
\item{LSST Verification Cluster (LSST-VC) with Slurm Job Scheduler}
\item{Submit and compute nodes with read/write access to various GPFS shared filesystems:}
\begin{enumerate}
\item{Filesystem containing the software stack}
\item{Filesystem for the submit side temporary outputs}
\item{Filesystem being used by the prototype Data Backbone. (This means that the framework can use a \texttt{cp} transfer protocol between the job and the Data Backbone and does not require additional transfer services to be running.)}
\item{Filesystem for the individual job scratch directories.}
\end{enumerate}
\item{Single node Oracle database (version 12c)} 
\item{Submit node (lsst-dev01.ncsa.illinois.edu) running the HTCondor Central Manager (version 8.7.3).}
\end{itemize}

\paragraph{Software}\label{sec:software}
All the necessary software will be pre-installed.   The software
includes the science pipeline codes as well as the Data Management
system codes (Batch Processing Service, Data Backbone).

For LDM-503-2, Python 2 versions of software will be used.  The
science pipeline codes will be provided via the LSST DM Software
Stack, release 14.0.  The Batch Processing Service and the Data Backbone 
are initial versions using the DESDM Framework packages.  LSST-specific
plugins as well as DRP pipeline integration codes are also pre-installed. 
All python DESDM Framework packages, plugins and integration codes exist
in the lsst-dm github with tag 1.01. The DESDM prerequisites come from 
the official DESDM eups package firstcut Y4N+5.   They are installed
using DESDM's eups install process.

The ticket branch \texttt{tickets/DM-12291} of the LSST Software Stack
packages \texttt{meas{\_}base}, \texttt{pipe{\_}tasks}, and
\texttt{obs{\_}subaru} will be used to change the patch ID naming
convention.  This is due to issues of having commas in the filenames
and data IDs, as discussed in \jira{RFC-361}; the solution has been
agreed in \jira{RFC-365} for future implementation in \jira{DM-11874},
\jira{DM-11875}, and \jira{DM-11876}.

For LDM-503-2, the software will be installed into the GPFS space
at \texttt{/project/production/} on LSST-VC.  A single eups prototype
package will be defined to encompass the above mentioned software.

\subsubsection{Input specification}\label{sec:input}

A small number of selected tracts of the Hyper Suprime-Cam dataset will be used along with appropriate calibration datasets.

For LDM-503-2, the three tracts of the Hyper Suprime-Cam "RC" dataset, as defined in DMTR-31, will be used.
The calibration dataset will be the 20170105 version, as in DMTR-31.   Raw files known to fail processCcd 
will be blacklisted.

\subsubsection{Output specification}

The output data products will be available from the Data Backbone.

For LDM-503-2, the output data products will be available on the LSST-VC via a shared filesystem and advanced data discovery is done via SQL queries against the Oracle database.


\subsubsection{Test configuration}\label{sec:configuration}

For each test, the science configuration and operations configuration of the pipeline must be specified.

\paragraph{Science configuration}
\begin{enumerate}
    \item{What pipeline steps are to be executed?}
    \begin{enumerate}
        \item{For LDM-503-2 test, the following pipeline steps will be executed: }
        \begin{itemize}
        \item{\texttt{processCcd}}
        \item{\texttt{makeCoaddTempExp}}
        \item{\texttt{assembleCoadd}}
        \item{\texttt{detectCoaddSources}}
        \item{\texttt{mergeCoaddDetections}}
        \item{\texttt{measureCoaddSources}}
        \item{\texttt{mergeCoaddMeasurements}}
        \item{\texttt{forcedPhotCoadd}}
        \end{itemize}
    \end{enumerate}
    \item{What metadata needs to be saved for each data product type \S\ref{drp-00-10-items}?}
    \begin{itemize}
        \item{For LDM-503-2 test, basic metadata such are visit, ccd, patch, tract, filter are required as appropriate for each data product type.   Future milestones will expand this to include other science values.}
    \end{itemize}
    \item{Any non-default task configuration to be used?} \\
        For LDM-503-2 test, use the HSC default configs from the stack, 
        including the task defaults and \texttt{obs{\_}subaru}â€™s overrides, except:
        \begin{itemize}
            \item{Since not running \texttt{MosaicTask}, set \texttt{doApplyUberCal=False} for \texttt{makeCoaddTempExp.py} and \texttt{assembleCoadd.py}.}
            \item{In \texttt{makeCoaddTempExp.py}, retarget the \texttt{select} subtask to \texttt{PsfWcsSelectImagesTask}, similar to \texttt{coaddDriver.py} in \texttt{pipe{\_}drivers}.}
        \end{itemize}
\end{enumerate}
\paragraph{Operations configuration}
\begin{enumerate}
    \item{Any special Batch Processing Service configuration to be used?} \\
    For LDM-503-2 test,
    \begin{enumerate}
        \item{Each tract will be executed on its own set of nodes (obtained using allocateNodes.py) as opposed to a single larger set of nodes shared by all tracts.}
    \end{enumerate}

\end{enumerate}

\subsubsection{Procedure}

Executing a pipeline successfully through the Batch Processing
Serivce means that the processing attempt passed both basic data
completeness and integrity checks (\S\ref{sec:basic_checks}) as well as first-order science
QA (\S\ref{sec:first-order-qa}) performed by Production Scientists.


\paragraph{Setup}
\begin{enumerate}
  \item{The LSST Science Pipelines and the DESDM Framework, plugins, and integration codes as described in \S\ref{sec:software} have already been installed.   The Operator merely sets up the expanded stack using eups.}
  \item{Input raw and calibration data must exist in the Data Backbone. If not, the data will be ingested into Data Backbone.}  
  \item{The operator tags and blacklists input data as appropriate for test (\S\ref{sec:input}).}
  \item{Given the LSST Science Pipelines version, the operator will generate the full config files and schema files (\S\ref{sec:configuration}), which are then ingested into the Data Backbone.}

  \item{Write a DRP pipeline workflow definition file from scratch or modify an existing file from github making its operations- and dataset-specific inputs match this test.}

  \begin{enumerate}
    \item{For LDM-503-2, the pipeline workflow definition file is written in a workflow control language (wcl) format as used by the DESDM Framework.}
  \end{enumerate}
  \item{Make special hardware requests (e.g., disk or compute node reservations) if needed.}
\end{enumerate}

\paragraph{Execution}
\begin{enumerate}
  \item{If HTCondor processes are not already running, start HTCondor processes on compute nodes.  This step makes the compute nodes join the HTCondor Central Manager to create a working HTCondor Pool.}
  \item{The execution for each tract of the input data in \S\ref{sec:input} will be submitted to the hardware in \S\ref{sec:hardware} using the configuration in \S\ref{sec:configuration}.}
  \item{During execution, the operator will use software to demonstrate the ability to check the processing status.}
  \begin{enumerate}
    \item{For LDM-503-2, the available Batch Production Service monitoring software consists of two commands: one to summarize currently submitted processing, one to get more details of single submission.}
  \end{enumerate}
  \item{If the processing attempt completes, the attempt is marked as completed and tagged as potential for the next test steps.  These campaign tags are used to make pre-release QA queries simpler.}
  \item{If the processing attempt fails, the attempt is marked as failed.}
  \item{If the processing attempt fails due to certain infrastructure configuration or transient instability (e.g., network blips), the processing of the tract can be tried again after the problem is resolved.}
\end{enumerate}

\paragraph{Basic Data Completeness and Integrity Checks}\label{basic_checks}
\begin{enumerate}
  \item{When the execution finishes, the success of the execution will be verified by checking the existence of the expected output data.}
    \begin{enumerate}

       \item{For each of the expected data products types (listed
       in \S\ref{drp-00-10-items}) and each of the expected units
       (visits, patches, etc), verify the data product is in the 
       Data Backbone and has filesize greater than zero via DB 
       queries.}

       \item{Verify the physical and location information in Data
       Backbone DB matches the Data Backbone filesystem and
       vice-versa.}

    \end{enumerate}
  \item{Check that for each data product type has appropriate metadata saved for each file as defined in \S\ref{sec:configuration}}
  \item{Check provenance}
    \begin{enumerate}
        \item{Verify that each file can be linked with the step and processing attempt that created it via the Data Backbone.}
        \item{Verify that the information linking input files to each step was saved to the Oracle database.}
    \end{enumerate}
  \item{Check runtime metrics, such as the number of executions of each code, wallclock per step, wallclock per tract,
        etc.}
\end{enumerate}

\paragraph{First-order Science QA}\label{first-order-qa}
\begin{enumerate}
  \item{Production Scientist will perform first-order science quality assurance.}
  \item{These tests were not scheduled as part of LDM-503-2, but will be specified and used in future work.
  For attempts that pass these future first-order science QA steps will be executed through }
\end{enumerate}
